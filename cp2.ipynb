{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JluDkKDa0AWq",
        "outputId": "d553e9dc-6dba-4a01-fc7f-b58066ed3a34"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1015340251.py, line 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install seaborn\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6SuYl96_18Ym"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import glob as gb\n",
        "# import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "h9DxqT3V2XZF"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 128\n",
        "SEED = 1000\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "TRAIN_DIR ='F:\\cvpr\\cpp2 data set/train'\n",
        "TEST_DIR = 'F:\\cvpr\\cpp2 data set/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "ewVfqebU3PLq",
        "outputId": "298a93e4-bc60-4d3a-c981-b8c65e9327a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "137\n"
          ]
        }
      ],
      "source": [
        "categories = []\n",
        "class_count = []\n",
        "train_exm = 0\n",
        "for f in os.listdir(TRAIN_DIR):\n",
        "    files = gb.glob(pathname=str(TRAIN_DIR  + '//' + f + '/*.jpg'))\n",
        "    categories.append(f)\n",
        "    class_count.append(len(files))\n",
        "    train_exm += len(files)\n",
        "\n",
        "# sns.barplot(x=categories, y=class_count).set_title(\"distribution of train data\")\n",
        "\n",
        "plt.show()\n",
        "print(train_exm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eN5FeZgN3wuU"
      },
      "outputs": [],
      "source": [
        "train_gen = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    validation_split = 0.2,\n",
        "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
        "    # dtype = tf.float32\n",
        ")\n",
        "\n",
        "test_gen = ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
        "    # dtype = tf.float32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qbrh35THQHh8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRK0fiDI6vHV",
        "outputId": "a16144e2-e026-4cba-d040-16c03e5dc445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 110 images belonging to 2 classes.\n",
            "Found 27 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_batch = train_gen.flow_from_directory(\n",
        "    directory=TRAIN_DIR,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'sparse',\n",
        "    subset = 'training',\n",
        "    seed = SEED\n",
        ")\n",
        "valid_batch = train_gen.flow_from_directory(\n",
        "    directory=TRAIN_DIR,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'sparse',\n",
        "    subset = 'validation',\n",
        "    seed = SEED\n",
        ")\n",
        "test_batch = test_gen.flow_from_directory(\n",
        "    directory=TEST_DIR,\n",
        "    target_size = (IMG_SIZE, IMG_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    class_mode = 'sparse',\n",
        "    seed = SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTYB-f6sIlIk",
        "outputId": "023695e8-68bb-421e-ce6b-5d4f786fea70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "img_shape = (IMG_SIZE, IMG_SIZE)+(3,)\n",
        "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False,  weights='imagenet')\n",
        "base_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WITH FREEZING THE LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe7NnyzlJ9lh",
        "outputId": "9fdfdc1b-d7a6-49cb-92b9-b1e9fe256391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 15,142,213\n",
            "Trainable params: 15,142,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "izDp5oSSM8Q4"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        "    \n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "nUYPwCW1OCTf",
        "outputId": "bdc7ba1a-7868-49da-bc1b-e37049b18a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 34s 3s/step - loss: 5.5307 - accuracy: 0.4216 - val_loss: 0.7634 - val_accuracy: 0.5417\n"
          ]
        }
      ],
      "source": [
        "h = model.fit(\n",
        "    train_batch,\n",
        "    steps_per_epoch = 110 // BATCH_SIZE,\n",
        "    validation_data=valid_batch,\n",
        "    validation_steps=27 // BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Without freezing the layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "wIxVMSgGPlEp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 15,142,213\n",
            "Trainable params: 15,142,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE, 3))\n",
        "x = base_model(inputs, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, output)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
        "    metrics=['accuracy']\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 32s 2s/step - loss: 16.1817 - accuracy: 0.4608 - val_loss: 0.7983 - val_accuracy: 0.5833\n"
          ]
        }
      ],
      "source": [
        "h = model.fit(\n",
        "    train_batch,\n",
        "    steps_per_epoch = 110 // BATCH_SIZE,\n",
        "    validation_data=valid_batch,\n",
        "    validation_steps=27 // BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Though i have user customised small dataset from cifar-10 dataset. I have got the higher accuracy in without freezing the base model top layers which is 58% and with freezing the base model layers get 53% accuracy. The reason might be overfitting.  In without freezing process my datas are all trained and tested thats why its accuracy increased."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
